{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nq5j86rtWxw8"
   },
   "source": [
    "# MP-3 Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gf4AIWLgVMth"
   },
   "source": [
    "> **Instructions**\n",
    ">\n",
    ">  Your Name:\n",
    ">\n",
    ">  Your Groupmate:\n",
    ">\n",
    ">  Other acknowledgements/resources used:\n",
    ">\n",
    ">\n",
    "> There will be ✏️ checkpoints with blank cells for you to fill in. You are responsible for submitting an attempt for every checkpoint in this notebook.\n",
    ">\n",
    ">  You are encouraged to work on these in groups. However, **each student will write their own solutions and writeups and upload both to Canvas individually**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsf-2yHS0xCH"
   },
   "source": [
    "## Getting Started\n",
    "\n",
    "If you encounter any import errors, you may need to run the following command within this notebook:\n",
    "\n",
    "```\n",
    "!pip install psmpy statsmodels nltk seaborn\n",
    "```\n",
    "\n",
    "add any additional packages throwing you errors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5568,
     "status": "ok",
     "timestamp": 1740773996870,
     "user": {
      "displayName": "Charlotte Lambert",
      "userId": "05396479922092236639"
     },
     "user_tz": 300
    },
    "id": "j4tNsvzG0xCI",
    "outputId": "92b6d253-b371-49c9-d481-0a9735dd9e91",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Install a package for propensity score matching\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import statsmodels.formula.api as smf\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9LCAyrd0xCJ"
   },
   "source": [
    "First, we'll load the dataset. Each row is a single post made in r/aww in the year 2022. A few columns to note:\n",
    "\n",
    "- `id`: The id of the post\n",
    "- `author`: The author's display name\n",
    "- `created_utc`: Timestamp of when the post was created\n",
    "- `gilded`: The number of gold the post received\n",
    "- `score`: The number of aggregated upvotes and downvotes the post received\n",
    "- `title`: The original title of the post\n",
    "\n",
    "We'll exclude all the comments by accounts since deleted to respect author privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 12882,
     "status": "ok",
     "timestamp": 1740774009750,
     "user": {
      "displayName": "Charlotte Lambert",
      "userId": "05396479922092236639"
     },
     "user_tz": 300
    },
    "id": "HgVfnzmJn7rr",
    "outputId": "8d420532-b471-4b88-f7ec-4d09d574ee94"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"r_aww_subs_2022.csv.xz\",\n",
    "                 usecols = ['id','author','created_utc',\n",
    "                            'gilded', 'score', 'title']\n",
    "                )\n",
    "\n",
    "# Drop posts made by deleted accounts\n",
    "df = df.query(f\"author != '[deleted]'\").reset_index(drop=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQfDKF2OeIv9"
   },
   "source": [
    "### Adding Data\n",
    "\n",
    "We're going to want some more information about our posts to help us find appropriate matches.\n",
    "\n",
    "* `weeks_since_start`: which week the post was created in since the earliest post in this dataset.\n",
    "* `title_length`: the length of the post title to give some metadata about the post content.\n",
    "* `date`: the date of the post formatted nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFaNVtkteIv9"
   },
   "outputs": [],
   "source": [
    "# The number of seconds in a week\n",
    "ONE_WEEK = 60 * 60 * 24 * 7\n",
    "\n",
    "df = df.assign(date=lambda df: pd.to_datetime(df.created_utc, unit=\"s\"))\n",
    "\n",
    "# Also keep track of when this post was made\n",
    "df['weeks_since_start'] = (df.created_utc - df.created_utc.min()) // ONE_WEEK\n",
    "\n",
    "# Length of the title in characters\n",
    "df['title_length'] = df.title.apply(len)\n",
    "df = df.drop(columns=['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isxJxSxj0xCK"
   },
   "source": [
    "### ✏️ **Checkpoint 1 (1 point)**\n",
    "\n",
    "There are two tasks for this checkpoint.\n",
    "\n",
    "**Part 1:** Plot a histogram of the number of posts over time (i.e., using `date`). (0.5 points)\n",
    "\n",
    "**Part 2:** In the writeup, state what you notice about the overall trends from the plot. (0.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71d9CwNx-kGv"
   },
   "outputs": [],
   "source": [
    "# Part 1: Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNLZAG4sXUZb"
   },
   "source": [
    "**Part 2:** *Fill in this cell with your observations*\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUDcQf9mY_KZ"
   },
   "source": [
    "## Separating the Treatment and Control Authors\n",
    "\n",
    "In order to answer our RQs using a causal inference setup, we need to identify a treatment group and a control group. We can then find appropriate matches between the groups to make causal claims about how receiving the treatment (i.e., high score) changes future user behavior.\n",
    "\n",
    "With that in mind:\n",
    "* Our **treatment** group: all users who have recieved high score on at least one post in the dataset\n",
    "* Our **control** group: all users who have made at least one post in the dataset but not received high score on any of them. This is also referred to as the *placebo*.\n",
    "\n",
    "We'll start by identifying what it means to receive \"high score.\" We can do this in lots of ways, but for this MP we're going to pick the 2,000 highest scores to call \"treated\". A small treatment group like this makes sure the rest of this MP runs without too much delay!\n",
    "\n",
    "After running the cell below, we'll have a boolean `high_score` column indicating whether the given post received high score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['score', 'created_utc'], ascending=[False, True]).assign(high_score=[True]*2000 + [False]*(len(df) - 2000))\n",
    "df[['score','high_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHIor7jNY_Kb"
   },
   "source": [
    "### ✏️ **Checkpoint 2 (1 point)**\n",
    "\n",
    "You have two tasks:\n",
    "\n",
    "**Part 1:** Compile lists of unique authors in the treatment and control groups. (0.5 points)\n",
    "\n",
    "**Part 2:** Create a new column in `df` called `condition` and assign each row a 0 if it corresponds to a post made by a control author, and a 1 for treated authors. *Note: this is different than the top 2,000 scores!* (0.5 points)\n",
    "\n",
    "*Hint: you can use the `.loc` function to set values for a specific column based on a condition (see [Setting values](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html#setting-values)).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YpZDd-V6ZEi7"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "treated_authors = []\n",
    "control_authors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pv6j-SCJNNM4"
   },
   "source": [
    "##### Verify Your Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3375,
     "status": "ok",
     "timestamp": 1740774022473,
     "user": {
      "displayName": "Charlotte Lambert",
      "userId": "05396479922092236639"
     },
     "user_tz": 300
    },
    "id": "lzmhvntsZXtW",
    "outputId": "aba9c296-1003-4a93-c4af-1137063a779c"
   },
   "outputs": [],
   "source": [
    "assert len(treated_authors) == 1247, f'Number of treated authors not quite right ({len(treated_authors):,}).'\n",
    "assert len(df.query('condition == 1')) == 13_972, f'Number of posts by treated authors not quite right ({len(df.query(\"treated == 1\")):,}).'\n",
    "assert all(df.query('condition == 1').groupby(\"author\")['high_score'].sum() > 0), f'Some treated authors have no highly-scored posts!'\n",
    "\n",
    "assert len(control_authors) == 105_569, f'Number of control authors not quite right ({len(control_authors):,}).'\n",
    "assert len(df.query('condition == 0')) == 207_741, f'Number of posts by control authors not quite right ({len(df.query(\"treated == 0\")):,}).'\n",
    "assert all(df.query('condition == 0').groupby(\"author\")['high_score'].sum() == 0), 'Some control authors have highly-scored posts!'\n",
    "\n",
    "print('All tests passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_UnssCNcNcY"
   },
   "source": [
    "### Identifying Candidates for Matching\n",
    "\n",
    "Now we've identified all the authors who received the treatment at some point and those that didn't. But let's say an author made multiple posts that got high score, do they all count as treatments?\n",
    "\n",
    "For this MP, we'll make the simplifying assumption that **an author's first highly-scored post is their only treatment**. For the control set, we will select **a random placebo post from each control author**. We acknowledge, however, that our dataset is an arbitrary point in time, and their first gilded post within this specific window is not necessarily their first gilded post of all time.\n",
    "\n",
    "Next we'll isolate those treatment and placebo posts into a dataframe of matching candidates, `df_candidates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates = pd.concat([\n",
    "    # Treatment candidates: a user's first highly-scored post\n",
    "    df.query('high_score == 1 and condition == 1').sort_values(by='created_utc').drop_duplicates(subset=['author'], keep='first'),\n",
    "    # Control candidates: a random placebo post from each control author\n",
    "    df.query('high_score == 0 and condition == 0').sample(frac=1, random_state=10).drop_duplicates(subset=['author'])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-Ps6BQ6a-Dh"
   },
   "source": [
    "## Propensity Score Matching\n",
    "\n",
    "Now that we have our candidates, we have to figure out how to pair each treatment candidate with a *similar enough* control candidate. We can do this through **Propensity Score Matching (PSM)**, which uses logistic regression and a set of covariates to assign each candidate with a likelihood of being treated, regardless of whether it's a treatment or control sample.\n",
    "\n",
    "For example, imagine someone posted a really high-quality post, but for whatever reason, it went under the radar and did not receive many upvotes. This is a perfect control sample because it probably *should* have been highly scored, but wasn't, so it may have a similar propensity score to an actual highly scored post. With high quality matches, when we look at how treated authors' behavior changes after receiving treatment, we can attribute those effects to the treatment itself.\n",
    "\n",
    "For this lab, we're considering the following covariates:\n",
    "* `baseline_num_posts`: the number of posts made by the author in the 2 weeks prior to treatment/placebo\n",
    "* `baseline_avg_score`: the average score on all posts made by the author in the 2 weeks prior to treatment/placebo\n",
    "* `baseline_avg_title_length`: the average length of post titles by the author\n",
    "* `weeks_since_start`: which week this post was made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXkf-uafeIv-"
   },
   "source": [
    "#### Calculating Covariates\n",
    "\n",
    "Because our covariates focus on the 2 weeks of behavior prior to treatment/placebo, we'll need to find all the posts made by each author in that window.\n",
    "\n",
    "We'll use the Pandas `merge` function to match up each candidate with *all* its author's other posts in the dataset. Then we can filter out all the posts that happened 2 weeks prior to treatment/placebo and take some aggregates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 11455,
     "status": "ok",
     "timestamp": 1740774034306,
     "user": {
      "displayName": "Charlotte Lambert",
      "userId": "05396479922092236639"
     },
     "user_tz": 300
    },
    "id": "af0xtnv9tdgx",
    "outputId": "b07ef44c-0c0c-4d5a-e13c-b7cff31777b2"
   },
   "outputs": [],
   "source": [
    "# Get pre- and post-treatment/placebo behavior for all candidate posts\n",
    "df_agg = df_candidates.merge(df[['id','author', 'created_utc', 'score', 'title_length']],\n",
    "                  on='author', suffixes=('', '_agg'), how='left'\n",
    "                  ).query('id != id_agg')\n",
    "\n",
    "# Define the week based on when each post ocurred relative to the author's other posts\n",
    "df_agg['week'] = (df_agg['created_utc_agg'] - df_agg['created_utc']) // ONE_WEEK\n",
    "\n",
    "# Aggregate covariate for matching in the two weeks prior to treatment/placebo\n",
    "baseline = df_agg.query('-2 <= week < 0').groupby([\"id\"]).agg(\n",
    "    baseline_num_posts=(\"created_utc\", \"count\"),\n",
    "    baseline_avg_score=(\"score_agg\", \"mean\"),\n",
    "    baseline_avg_title_length=(\"title_length_agg\", \"mean\")\n",
    ")\n",
    "\n",
    "baseline.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SusudffeIv-"
   },
   "source": [
    "Now let's add those covariates back into our candidate dataframe so we can use them in our matching!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "executionInfo": {
     "elapsed": 1094,
     "status": "ok",
     "timestamp": 1740774035399,
     "user": {
      "displayName": "Charlotte Lambert",
      "userId": "05396479922092236639"
     },
     "user_tz": 300
    },
    "id": "G_XNlOHQeIv-",
    "outputId": "ac307d9c-9516-4882-bae1-3a01d072af90"
   },
   "outputs": [],
   "source": [
    "df_candidates = df_candidates.merge(baseline, on='id')\n",
    "df_candidates.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCYRPyHmat7o"
   },
   "source": [
    "Let's actually perform matching now! This code will take our candidates and the relevant covariates and find each treatment candidate a single control match. This library is essentially computing a post's propensity of being treated by running a logistic regression model like this:\n",
    "```\n",
    "condition ~ baseline_num_posts + baseline_avg_score + weeks_since_start + baseline_avg_title_length\n",
    "```\n",
    "Then, we perform K-Nearest Neighbor (KNN) matching and drop any unmatched treatment or control candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EoDUK5QWeIv_"
   },
   "outputs": [],
   "source": [
    "from psmpy import PsmPy\n",
    "from psmpy.functions import cohenD\n",
    "from psmpy.plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "executionInfo": {
     "elapsed": 45147,
     "status": "ok",
     "timestamp": 1740774085812,
     "user": {
      "displayName": "Charlotte Lambert",
      "userId": "05396479922092236639"
     },
     "user_tz": 300
    },
    "id": "YckgEQL85RRd",
    "outputId": "e45ac9a5-2989-4a1e-edb3-eb74b8ce3d8d"
   },
   "outputs": [],
   "source": [
    "# Perform matching\n",
    "psm = PsmPy(df_candidates[['id','condition', 'baseline_num_posts','baseline_avg_score','weeks_since_start', 'baseline_avg_title_length']],\n",
    "            treatment='condition', indx='id', exclude = [])\n",
    "psm.logistic_ps(balance = True)\n",
    "psm.knn_matched(matcher='propensity_logit', replacement=False, caliper=None, drop_unmatched=True)\n",
    "\n",
    "# Grab matched_IDs and propensity scores\n",
    "df_matched = df_candidates.merge(psm.df_matched[['id', 'propensity_score','propensity_logit', 'matched_ID']],\n",
    "                    on=['id'], how='inner')\n",
    "\n",
    "df_matched.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAZo5WBqajhp"
   },
   "source": [
    "### Measuring Match Quality\n",
    "\n",
    "Now we have treatment-control pairs, but are they well-matched? We can measure the **Standardized Mean Difference (SMD)** of each of our covariates before and after matching to estimate match quality. Low SMDs indicate little difference between the treatment group and control group on a given covariate. Ideally, matching will decrease the SMD for each covariate and not exceed a certain threshold. For this MP, we'll consider **covariates to be well matched if they do not exceed an SMD of 0.25**.\n",
    "\n",
    "The `PsmPy` library gives us a nice function to plot the SMDs, let's see if our matches look good!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 293,
     "status": "ok",
     "timestamp": 1740774086107,
     "user": {
      "displayName": "Charlotte Lambert",
      "userId": "05396479922092236639"
     },
     "user_tz": 300
    },
    "id": "k0KYqt7u6-aD",
    "outputId": "466a099b-69c1-451d-abd0-ab4bbccf8673"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Plot SMDs by covariate\n",
    "psm.effect_size_plot(before_color='#FCB754', after_color='#3EC8FB')\n",
    "\n",
    "# Add line for threshold of match quality\n",
    "plt.axvline(0.25, linestyle='--', color='red')\n",
    "\n",
    "# # Adjust labels\n",
    "plt.title('Match Quality')\n",
    "plt.xlabel('Standardized Mean Difference (SMD)')\n",
    "plt.ylabel('Covariate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JoYVJZdHeIv_"
   },
   "source": [
    "### ✏️ **Checkpoint 3 (2 points)**\n",
    "\n",
    "Let's improve our match quality! Identify the covariate(s) with poor match quality and do the following:\n",
    "\n",
    "**Part 1:** Plot a histogram (using `sns.histplot()`) of any poorly matched covariate(s) over the treatment and control candidates (i.e., pre-matched data, `df_candidates`). Do not plot any well-matched covariates. (0.5 points)\n",
    "\n",
    "**Part 2:** Describe the shape of this distribution and state how we can adjust the shape to be more normally distributed. (0.5 points)\n",
    "\n",
    "**Part 3:** Use the approach from part 2 to normalize the covariate's data. Then, re-match the data with the adjusted covariate and report match quality (i.e., plot SMDs as above). (1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tF0LkV3KeIv_"
   },
   "outputs": [],
   "source": [
    "# Part 1: Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6RrcR7reIv_"
   },
   "source": [
    "**Part 2: Fill in this cell**\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3cKtErMAh0H"
   },
   "source": [
    "## Wilcoxon Signed-Rank Test\n",
    "\n",
    "Let's return to our RQs and see if the treated users' posting rate and average score changes significantly more after treatment compared to their control matches.\n",
    "\n",
    "To do this, we'll employ a statistical test called the **Wilcoxon signed-rank test**, which allows us to determine if the difference between outcomes for paired samples (e.g., our matches) is stastistically signifcant.\n",
    "\n",
    "The null hypothesis for our test is as follows:\n",
    "> **The median of the paired differences is zero**\n",
    "\n",
    "In our context, that means treated users' posting rate and average score change by the same amount as the control users'.\n",
    "\n",
    "To carry out this test, we first need to grab each matched user's posts before and after their treatment/placebo so we can examine how their behavior changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "executionInfo": {
     "elapsed": 152,
     "status": "ok",
     "timestamp": 1740774123241,
     "user": {
      "displayName": "Charlotte Lambert",
      "userId": "05396479922092236639"
     },
     "user_tz": 300
    },
    "id": "Ffuzef78ctq3",
    "outputId": "e1c2b70c-d81e-4114-97e1-3c5c05384418"
   },
   "outputs": [],
   "source": [
    "# Get pre- and post-treatment/placebo behavior for all candidate posts\n",
    "df_pre_post = df_matched.merge(df[['id','author', 'high_score', 'created_utc', 'score']],\n",
    "                  on='author', suffixes=('', '_agg')\n",
    "                  ).query('id != id_agg')\n",
    "\n",
    "# Add a boolean for whether the post was pre- or post-treatment\n",
    "df_pre_post['post_treatment'] = df_pre_post['created_utc_agg'] >= df_pre_post['created_utc']\n",
    "df_pre_post.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBDYNWF7eIwA"
   },
   "source": [
    "Now we want to compute a delta for each user and each outcome. Essentially, how much did their `num_posts` and `avg_score` change after treatment/placebo? We can use the pandas [`pivot_table()`](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html#pivot-and-pivot-table) function to make a table with a row for each post, and columns for each combination of outcome and `post_treatment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1740774123312,
     "user": {
      "displayName": "Charlotte Lambert",
      "userId": "05396479922092236639"
     },
     "user_tz": 300
    },
    "id": "KizFA22geIwA",
    "outputId": "0043210b-c7b9-4fd6-ad8c-1e2164987dd1"
   },
   "outputs": [],
   "source": [
    "# Compare pre and post treatment values for each outcome\n",
    "df_pre_post = df_pre_post.groupby(['id','author','post_treatment']).agg(\n",
    "    avg_score=('score_agg','mean'),\n",
    "    num_posts=('created_utc','count'),\n",
    ").reset_index()\n",
    "\n",
    "# Pivot the table based on 'post_treatment' (0 and 1)\n",
    "df_pre_post = df_pre_post.pivot_table(index=['id', 'author'], columns='post_treatment', values=['avg_score', 'num_posts'])\n",
    "\n",
    "# Rename the columns\n",
    "df_pre_post.columns = [f'{col[0]}_{\"post\" if col[1] else \"pre\"}' for col in df_pre_post.columns]\n",
    "\n",
    "df_pre_post.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYO6hXfIeIwA"
   },
   "source": [
    "Now let's compute those deltas! After this cell, we'll have the following new columns:\n",
    "* `avg_score_delta`: the difference between an author's average score before and after treatment/placebo\n",
    "* `num_posts_delta`: the difference between an author's number of posts before and after treatment/placebo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1740774123351,
     "user": {
      "displayName": "Charlotte Lambert",
      "userId": "05396479922092236639"
     },
     "user_tz": 300
    },
    "id": "kJuTC8poeIwA",
    "outputId": "16c3f692-3009-4c13-c110-bca06098fac1"
   },
   "outputs": [],
   "source": [
    "# Fill in 0s if there is no posting data for an author\n",
    "df_pre_post[['num_posts_pre','num_posts_post']] = df_pre_post[['num_posts_pre','num_posts_post']].fillna(0)\n",
    "\n",
    "# Compute the differences (post-treatment minus pre-treatment)\n",
    "df_pre_post['avg_score_delta'] = df_pre_post['avg_score_post'] - df_pre_post['avg_score_pre']\n",
    "df_pre_post['num_posts_delta'] = df_pre_post['num_posts_post'] - df_pre_post['num_posts_pre']\n",
    "\n",
    "df_pre_post = df_pre_post[['avg_score_delta','num_posts_delta']]\n",
    "\n",
    "df_pre_post.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKTRIXA_eIwA"
   },
   "source": [
    "Next, our Wilcoxon signed-rank test is paired, meaning we want to compare the delta for each user with the delta for their matched user. Let's modify the dataframe to have one row per pair. Columns with a `_t` suffix correspond to the treatment author and those with a `_c` suffix correspond to the control match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "executionInfo": {
     "elapsed": 99,
     "status": "ok",
     "timestamp": 1740774123455,
     "user": {
      "displayName": "Charlotte Lambert",
      "userId": "05396479922092236639"
     },
     "user_tz": 300
    },
    "id": "jKdYImh0eIwA",
    "outputId": "87401ed9-2540-4318-bb23-9e17e9676886"
   },
   "outputs": [],
   "source": [
    "# Bring back condition information\n",
    "df_pre_post = df_pre_post.merge(df_matched[['id','condition','matched_ID']], on=['id'])\n",
    "\n",
    "# Get control and treatment matches in the same row\n",
    "df_pre_post = df_pre_post.query('condition == 1').merge(df_pre_post.query('condition == 0'),\n",
    "                                           left_on='matched_ID',\n",
    "                                           right_on='id',\n",
    "                                           how='inner',\n",
    "                                           suffixes=('_t','_c'))\n",
    "df_pre_post.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✏️ **Checkpoint 4 (1 point)**\n",
    "\n",
    "Conduct Wilxocon signed-rank tests to answer the following: \n",
    "\n",
    "**Part 1:** Did the treatment group's `avg_score` and `num_posts` change significantly more or less after treatment than the control group's `avg_score` and `num_posts` after placebo? (0.5 points)\n",
    "\n",
    "**Part 2:** State which group has larger changes resulting from treatment/placebo and whether it is statistically significant using the significance level $\\alpha = 0.05$. (0.5 point)\n",
    "\n",
    "\n",
    "Utilize the `wilcoxon` function from [`scipy.stats`](https://docs.scipy.org/doc//scipy-1.10.1/reference/generated/scipy.stats.wilcoxon.html), imported below.\n",
    "\n",
    "*Hint: to determine which group, treatment or control, has a larger difference, look at the `alternative` parameter to the `wilcoxon` function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6RrcR7reIv_"
   },
   "source": [
    "**Part 2: Fill in this cell**\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up regression analysis\n",
    "\n",
    "To set up our dataset for the upcoming regression analysis, we'll need to do some organization of the data. The regression will take into account the treatment and control comments themselves, but also the pre- and post- treatment/placebo activity of the users, similar to the Wilcoxon signed-rank test, but with more granular time steps.\n",
    "\n",
    "First, let's merge our `matched_ID`s and other metadata about the matches back into the original dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_matched[['id','author','matched_ID','created_utc', \n",
    "                          'baseline_num_posts','baseline_avg_score','weeks_since_start', 'baseline_avg_title_length']\n",
    "                        ], on='author',suffixes=('', '_treatment'), how='inner')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SupngMt-V-9"
   },
   "source": [
    "### ✏️ **Checkpoint 5 (1 point)**\n",
    "\n",
    "Define a new column in `df` called `weeks_since_treatment` that stores an **integer** value representing how many weeks since an author's treatment/placebo time a post was made. This column represents relative time with respect to treatment/placebo, as opposed to absolute time (i.e., Jan 3, 2022).\n",
    "\n",
    "*Hint: each row is a post in the dataset which may or may not have been a treatment/control candidate. The column `created_utc_treatment` corresponds to the time the post's author received the treatment or placebo.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 912
    },
    "executionInfo": {
     "elapsed": 184,
     "status": "ok",
     "timestamp": 1741297693257,
     "user": {
      "displayName": "Charlotte Lambert",
      "userId": "05396479922092236639"
     },
     "user_tz": 360
    },
    "id": "yTlaY31u-V--",
    "outputId": "b8ec10eb-f874-4bc1-aa53-334bdc996495"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pv6j-SCJNNM4"
   },
   "source": [
    "##### Verify Your Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1741294186223,
     "user": {
      "displayName": "Charlotte Lambert",
      "userId": "05396479922092236639"
     },
     "user_tz": 360
    },
    "id": "rV6U1Gfb-V--",
    "outputId": "1e89729a-91c6-4754-83cd-962cd0b764e3"
   },
   "outputs": [],
   "source": [
    "# Test Cases\n",
    "assert df.query('id == \"yyzghh\"').weeks_since_treatment.values[0] == 44 and \\\n",
    "       df.query('id == \"t2ubfp\"').weeks_since_treatment.values[0] == -4 and \\\n",
    "       df.query('id == \"txhmmc\"').weeks_since_treatment.values[0] == 0, 'Something is not quite right. Double check your \"weeks_since_treatment\" calculation.'\n",
    "\n",
    "print('All tests passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmcxZ0XuF3CP"
   },
   "source": [
    "## Aggregating Data\n",
    "\n",
    "In the Wilcoxon signed-rank test, we aggregated all of an author's posting behavior before treatment/placebo and after. For the regression, we want a more granular analysis, so we're going to create weekly groupings so we can see how an author's behavior changes over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kr2fyOXk-V--"
   },
   "source": [
    "### ✏️ **Checkpoint 6 (1 point)**\n",
    "\n",
    "For this checkpoint, we're going to compute weekly statistics for each treatment or control sample.\n",
    "\n",
    "**Part 1:** Identify the rows of `df` corresponding to posts that did *NOT* receive the treatment or placebo. For this checkpoint, we only want to look at the posts made by treatment/control authors before or after treatment/placebo. Use [`pd.groupby`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) to group the result into weekly groups (using `weeks_since_treatment`) based on each treatment/control sample (indicated by `id_treatment`). *Hint: you can group by multiple columns!* (0.5 points)\n",
    "\n",
    "**Part 2:** For each sample-week pair, calculate the average weekly score (`avg_score`) and the average number of posts (`num_posts`). *Hint: use the [`agg()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html) function!* (0.5 points)\n",
    "\n",
    "Save these weekly aggregates in a dataframe called `df_weekly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9akEog1-V--"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "df_weekly = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pv6j-SCJNNM4"
   },
   "source": [
    "##### Verify Your Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1741294195227,
     "user": {
      "displayName": "Charlotte Lambert",
      "userId": "05396479922092236639"
     },
     "user_tz": 360
    },
    "id": "8b_LQeTv-V--",
    "outputId": "55a43d5e-658b-4338-a96f-22b29dbd482a"
   },
   "outputs": [],
   "source": [
    "# Test cases\n",
    "assert len(df_weekly) == 4_962, 'Unexpected number of weekly aggregates. Check your groupby'\n",
    "assert df_weekly.query('id_treatment == \"sllppw\" and weeks_since_treatment == 40').num_posts.values[0] == 2, 'Values in num_posts are not quite right.'\n",
    "assert df_weekly.query('id_treatment == \"t0entv\" and weeks_since_treatment == -2').avg_score.values[0] == 169, 'Values in avg_score are not quite right.'\n",
    "assert len(df_weekly.columns.union(set(['id_treatment', 'weeks_since_treatment', 'avg_score','num_posts']))) == 4, 'Columns in df_weekly are not quite right.'\n",
    "print('All tests passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've constructed the weekly aggregates, we'll add in the author and condition information so we have it for the regression.\n",
    "\n",
    "We'll also define a boolean `post_treatment` to indicate whether a post occurred before or after treatment/placebo time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekly = df_weekly.merge(df[['id_treatment','author', 'condition',\n",
    "                                'baseline_num_posts', 'baseline_avg_score', 'weeks_since_start', 'baseline_avg_title_length'\n",
    "                               ]].drop_duplicates(), on='id_treatment', how='left')\n",
    "\n",
    "df_weekly['post_treatment'] = df_weekly['weeks_since_treatment'] >= 0\n",
    "\n",
    "df_weekly.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdoqOjOuJE1e"
   },
   "source": [
    "To help visualize this dataframe, we can plot one author's posting behavior in our dataset. You'll see that they have posts in `df_weekly` from before their treatment (i.e., `weeks_since_treatment = 0`) and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "sns.lineplot(data = df_weekly.query('author == \"child-of-old-gods\"'), x='weeks_since_treatment', y='num_posts')\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.title('Posts by author \"child-of-old-gods\"')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8OiMF-4-V-_"
   },
   "source": [
    "## Difference-in-Differences Analysis\n",
    "\n",
    "As a reminder, we have two RQs we're hoping to answer:\n",
    "\n",
    "> **RQ 1: How does being highly upvoted on a post affect an author's posting frequency?**\n",
    ">\n",
    "> **RQ 2: How does being highly upvoted on a post affect an author's future score?**\n",
    "\n",
    "We can answer these questions using a **Difference-in-Differences (DiD)** approach, a technique that allows us to use the *counterfactual* (i.e., what would have happened to the treatment group if they hadn't been treated) to estimate causal effects. Here's a [helpful source](https://www.publichealth.columbia.edu/research/population-health-methods/difference-difference-estimation) on DiD regression.\n",
    "\n",
    "DiD analysis compares matched control users before/after placebo against what happened to the treated users after treatment. It's impossible to simultaneously apply the treatment and placebo to a single user, so we use DiD analysis to estimate that coutnerfactual using interaction terms. Here's a [helpful diagram](https://www.publichealth.columbia.edu/research/population-health-methods/difference-difference-estimation) to visualize how this works!\n",
    "\n",
    "The general form you should follow is:\n",
    "\n",
    "```\n",
    "outcome ~ post_treatment * condition + covariate_1 + covariate_2 + ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muEkPm2Q0xCX"
   },
   "source": [
    "###  ✏️️ **Checkpoint 7 (3 points)**\n",
    "\n",
    "For this checkpoint, you use a DiD regression setup to model the impact of the treatment on the outcomes (`avg_score` and `num_posts`), while controlling for the general trend in posting activity over time as well as differences between the treatment and control group.\n",
    "\n",
    "We will also incorporate the matching information into the analysis. One way would be to add a unique ID for each treatment-control pair, but that slows the model down significantly and adds a lot of hard-to-parse coefficients. Instead, **add the matching covariates as independent variables to the regression formula**. If you need a reminder, here are the covariates we matched on:\n",
    "* `baseline_num_posts`\n",
    "* `baseline_avg_score`\n",
    "* `weeks_since_start`\n",
    "* `baseline_avg_title_length`\n",
    "\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "**Part 1.** Since `avg_score` is a continuous variable, use [`smf.ols`](https://www.statsmodels.org/devel/generated/statsmodels.formula.api.ols.html) to fit an ordinary least squares model to the data for the `avg_score` outcome. (1 point)\n",
    "\n",
    "**Part 2.** Since `num_posts` is count data, use [`smf.negativebinomial`](https://www.statsmodels.org/devel/generated/statsmodels.formula.api.negativebinomial.html) to fit a negative binomial model to the data for the `num_posts` outcome. *Note: Poisson regression can also be used on count data, but our data exhibits [overdispersion](https://online.stat.psu.edu/stat504/lesson/7/7.3) which is handled better by Negative Binomial models.* (1 point)\n",
    "\n",
    "Note: You may see a bunch of `RuntimeWarning`s. You can safely ignore them.\n",
    "\n",
    "**Part 3.** Interpret the results, answering the following questions (with numbers). We're giving you a template solution since the interpretations can be tricky! Replace all the $\\beta$s with real coefficients, fill in the planks, and select one of the bolded words, where applicable (1 point)\n",
    "\n",
    "- How much higher is treated users' average score in comparison to control users, before any treatment? Is this result statistically significant?\n",
    "- How much do treated users post after treatment compared to before? What about control users?\n",
    "- How much higher are treated users' average score *and* number of posts compared to what they would have been if they had not received the treatment (i.e., the counterfactual)?\n",
    "\n",
    "*Hint: Negative Binomial models have an exponential link function, so the coefficients represent relative change. To interpret them more easily, you will have to exponentiate (i.e., `np.exp`) the coefficients and interpret the resulting number as a percent.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYj09e4D0xCX"
   },
   "outputs": [],
   "source": [
    "# Part 1: Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCf_Rpas-V-_"
   },
   "outputs": [],
   "source": [
    "# Part 2: Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxecJEOF-V-_"
   },
   "source": [
    "**Part 3: Fill in this cell**\n",
    "\n",
    "From the OLS model:\n",
    "* Treated users' average score is $\\beta_\\texttt{condition}$ upvotes **higher/lower** than control users' score, before treatment was applied.\n",
    "* Treated users' average score is $\\beta_\\texttt{post_treatment:condition}$ upvotes **higher/lower** than it would have been had they not received the treatment. \n",
    "\n",
    "From the Negative Binomial Model:\n",
    "* Treated users post $(\\exp(\\beta_\\texttt{post_treatment}+\\beta_\\texttt{post_treatment:condition}) - 1)*100 \\approx$ \\_\\_\\_% **more/less** after treatment. \n",
    "* Control users post $(\\exp(\\beta_\\texttt{post_treatment}) - 1)*100 \\approx$ \\_\\_\\_% **more/less** after treatment.\n",
    "* Treated users' number of posts is $(\\exp(\\beta_\\texttt{post_treatment:condition}) - 1)*100 \\approx$ \\_\\_\\_% **higher/lower** than it would have been had they not received the treatment.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ignWKcoVLyFg",
    "8oAHGySpL2mS",
    "Z2JZOl_nNLLK",
    "EGPE4AB5MVpB",
    "akmjHKyWMiPj",
    "82cFQ7aIMniE",
    "t3B3MoC-Mw9f"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
